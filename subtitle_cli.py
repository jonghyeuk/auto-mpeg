#!/usr/bin/env python3
"""
ìë§‰ ëª¨ë“œ CLI - MP4 + Whisper STT + ìë§‰ í•©ì„±

ì‚¬ìš©ë²•:
  python subtitle_cli.py input.mp4
  python subtitle_cli.py input.mp4 --output result.mp4
  python subtitle_cli.py input.mp4 --upscale 1080
  python subtitle_cli.py input.mp4 --opening opening.png --closing closing.png
"""

import argparse
import subprocess
import json
import math
import shutil
import textwrap
from pathlib import Path
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app import config
from app.modules.ffmpeg_renderer import FFmpegRenderer


class SubtitleCLI:
    """ìë§‰ ëª¨ë“œ CLI"""

    # ê¸°ë³¸ ì˜¤í”„ë‹/í´ë¡œì§• ì´ë¯¸ì§€ ê²½ë¡œ (ì €ì¥ì†Œ ë£¨íŠ¸ ê¸°ì¤€)
    DEFAULT_OPENING = project_root / "assets" / "opening.png"
    DEFAULT_CLOSING = project_root / "assets" / "closing.png"

    def __init__(self):
        self.temp_dir = config.TEMP_DIR / "subtitle_cli"
        self.temp_dir.mkdir(parents=True, exist_ok=True)

    def log(self, message):
        print(message)

    def extract_audio_from_video(self, video_path, output_audio_path):
        """MP4ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
        cmd = [
            "ffmpeg", "-y",
            "-i", str(video_path),
            "-vn",
            "-acodec", "pcm_s16le",
            "-ar", "16000",
            "-ac", "1",
            str(output_audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        return result.returncode == 0

    def get_audio_duration(self, audio_path):
        """ì˜¤ë””ì˜¤ ê¸¸ì´ ë°˜í™˜"""
        cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            str(audio_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        if result.returncode == 0 and result.stdout.strip():
            return float(result.stdout.strip())
        return 0

    def get_file_size_mb(self, file_path):
        """íŒŒì¼ í¬ê¸° (MB)"""
        return Path(file_path).stat().st_size / (1024 * 1024)

    def split_audio_into_chunks(self, audio_path, output_dir, chunk_duration=600):
        """ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        total_duration = self.get_audio_duration(audio_path)
        chunks = []
        start_time = 0
        chunk_index = 0

        while start_time < total_duration:
            chunk_path = output_dir / f"chunk_{chunk_index:03d}.wav"
            duration = min(chunk_duration, total_duration - start_time)

            cmd = [
                "ffmpeg", "-y",
                "-i", str(audio_path),
                "-ss", str(start_time),
                "-t", str(duration),
                "-acodec", "pcm_s16le",
                str(chunk_path)
            ]
            subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')

            if chunk_path.exists():
                chunks.append({
                    "path": str(chunk_path),
                    "start_time": start_time,
                    "duration": duration
                })

            start_time += chunk_duration
            chunk_index += 1

        return chunks

    def transcribe_single_chunk(self, audio_path, max_retries=3):
        """Whisperë¡œ ë‹¨ì¼ ì²­í¬ STT"""
        from openai import OpenAI
        import time

        client = OpenAI(api_key=config.OPENAI_API_KEY)
        retry_delays = [2, 8, 32]  # ui.pyì™€ ë™ì¼í•œ ì¬ì‹œë„ ê°„ê²©

        for attempt in range(max_retries):
            try:
                with open(audio_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="ko",  # í•œêµ­ì–´ ëª…ì‹œ
                        response_format="verbose_json",
                        timestamp_granularities=["segment"]
                    )
                return transcript
            except Exception as e:
                if attempt < max_retries - 1:
                    delay = retry_delays[attempt] if attempt < len(retry_delays) else 32
                    self.log(f"  âš ï¸ ì¬ì‹œë„ {attempt + 1}/{max_retries} ({delay}ì´ˆ í›„)...")
                    time.sleep(delay)
                else:
                    raise e

    def transcribe_with_whisper(self, audio_path, chunk_duration=600):
        """Whisper STT (ì²­í¬ ë¶„í•  ì§€ì›)"""
        audio_path = Path(audio_path)
        duration = self.get_audio_duration(audio_path)
        file_size_mb = self.get_file_size_mb(audio_path)

        self.log(f"  ğŸ“ ì˜¤ë””ì˜¤: {duration:.1f}ì´ˆ ({file_size_mb:.1f}MB)")

        # ì§§ì€ íŒŒì¼ì€ ë°”ë¡œ ì²˜ë¦¬
        if duration <= 600 and file_size_mb <= 20:
            return self.transcribe_single_chunk(audio_path)

        # ê¸´ íŒŒì¼ì€ ì²­í¬ë¡œ ë¶„í• 
        self.log(f"  ğŸ“¦ ì²­í¬ ë¶„í•  ì²˜ë¦¬")
        chunk_dir = self.temp_dir / "audio_chunks"
        chunks = self.split_audio_into_chunks(audio_path, chunk_dir, chunk_duration)
        self.log(f"  ğŸ“¦ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ë¨")

        all_segments = []
        for i, chunk in enumerate(chunks):
            self.log(f"  ğŸ¤ ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... (ì‹œì‘: {chunk['start_time']}ì´ˆ)")
            transcript = self.transcribe_single_chunk(chunk["path"])

            if hasattr(transcript, 'segments'):
                for seg in transcript.segments:
                    adjusted_seg = {
                        "start": seg.start + chunk["start_time"],
                        "end": seg.end + chunk["start_time"],
                        "text": seg.text
                    }
                    all_segments.append(adjusted_seg)

        self.log(f"  âœ“ ì´ {len(all_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œë¨")

        class MergedTranscript:
            def __init__(self, segments):
                self.segments = segments

        return MergedTranscript(all_segments)

    def format_subtitles(self, segments, max_chars=20):
        """ìë§‰ í¬ë§·íŒ…"""
        formatted = []
        for seg in segments:
            text = seg.get("corrected_text", seg.get("text", "")).strip()
            seg_copy = seg.copy()

            if len(text) <= max_chars:
                seg_copy["formatted_text"] = text
            else:
                lines = textwrap.wrap(text, width=max_chars, break_long_words=False)
                if len(lines) == 1 and len(text) > max_chars:
                    mid = len(text) // 2
                    lines = [text[:mid], text[mid:]]
                if len(lines) > 2:
                    lines = lines[:2]
                seg_copy["formatted_text"] = "\\N".join(lines)

            formatted.append(seg_copy)
        return formatted

    def generate_ass_subtitles(self, segments, output_path):
        """ASS ìë§‰ íŒŒì¼ ìƒì„±"""
        ass_header = """[Script Info]
Title: Auto Generated Subtitles
ScriptType: v4.00+
PlayResX: 1920
PlayResY: 1080
WrapStyle: 0

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Malgun Gothic,64,&H00FFFFFF,&H000000FF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,1,2,50,50,50,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

        def format_time(seconds):
            h = int(seconds // 3600)
            m = int((seconds % 3600) // 60)
            s = int(seconds % 60)
            cs = int((seconds % 1) * 100)
            return f"{h}:{m:02d}:{s:02d}.{cs:02d}"

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë¦¬
        sanitized = []
        for i, seg in enumerate(segments):
            seg_copy = seg.copy()
            start = seg_copy.get("start", 0)
            end = seg_copy.get("end", start + 3)
            if i > 0 and sanitized:
                prev_end = sanitized[-1].get("end", 0)
                if start < prev_end:
                    start = prev_end
            seg_copy["start"] = start
            seg_copy["end"] = end
            sanitized.append(seg_copy)

        # ì´ë²¤íŠ¸ ìƒì„± (ìŠ¤ë§ˆíŠ¸ í˜ì´ë“œ)
        events = []
        fade_ms = 200
        for i, seg in enumerate(sanitized):
            start = seg.get("start", 0)
            end = seg.get("end", start + 3)
            text = seg.get("formatted_text", seg.get("text", ""))

            is_first = (i == 0)
            is_last = (i == len(sanitized) - 1)

            if is_first and is_last:
                fade = f"{{\\fad({fade_ms},{fade_ms})}}"
            elif is_first:
                fade = f"{{\\fad({fade_ms},0)}}"
            elif is_last:
                fade = f"{{\\fad(0,{fade_ms})}}"
            else:
                fade = ""

            events.append(f"Dialogue: 0,{format_time(start)},{format_time(end)},Default,,0,0,0,,{fade}{text}")

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(ass_header + "\n".join(events))

        return output_path

    def burn_subtitles(self, video_path, ass_path, output_path):
        """ìë§‰ í•©ì„±"""
        renderer = FFmpegRenderer()
        encoder_args = renderer.get_video_encoder_args()

        ass_escaped = str(ass_path)
        if os.name == 'nt':
            ass_escaped = ass_escaped.replace("\\", "/").replace(":", "\\:")

        cmd = [
            "ffmpeg", "-y",
            "-fflags", "+genpts",
            "-i", str(video_path),
            "-vf", f"ass='{ass_escaped}'",
        ] + encoder_args + [
            "-c:a", "copy",
            "-avoid_negative_ts", "make_zero",
            "-movflags", "+faststart",
            str(output_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        return result.returncode == 0

    def upscale_video(self, input_path, output_path, target_height=1080):
        """ì˜ìƒ ì—…ìŠ¤ì¼€ì¼"""
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "v:0",
            "-show_entries", "stream=width,height",
            "-of", "csv=p=0",
            str(input_path)
        ]
        probe = subprocess.run(probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        width, height = map(int, probe.stdout.strip().split(','))

        if height >= target_height:
            shutil.copy(input_path, output_path)
            return True

        scale_factor = target_height / height
        new_width = int(width * scale_factor)
        new_width = new_width + (new_width % 2)

        renderer = FFmpegRenderer(crf=20)
        encoder_args = renderer.get_video_encoder_args()

        cmd = [
            "ffmpeg", "-y",
            "-i", str(input_path),
            "-vf", f"scale={new_width}:{target_height}:flags=lanczos",
        ] + encoder_args + [
            "-c:a", "copy",
            "-movflags", "+faststart",
            str(output_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        return result.returncode == 0

    def add_opening_closing(self, video_path, output_path, opening_image=None, closing_image=None, duration=3, fade_duration=1):
        """ì˜¤í”„ë‹/í´ë¡œì§• ì´ë¯¸ì§€ë¥¼ ì˜ìƒ ì•ë’¤ì— ì¶”ê°€ (í˜ì´ë“œ íš¨ê³¼)"""
        if not opening_image and not closing_image:
            shutil.copy(str(video_path), str(output_path))
            return True

        renderer = FFmpegRenderer()
        encoder_args = renderer.get_video_encoder_args()

        # ì›ë³¸ ì˜ìƒ ë¹„ë””ì˜¤ ì •ë³´
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "v:0",
            "-show_entries", "stream=width,height,r_frame_rate",
            "-of", "csv=p=0",
            str(video_path)
        ]
        probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        if probe_result.returncode != 0:
            self.log("  âš ï¸ ì˜ìƒ ì •ë³´ í™•ì¸ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©")
            shutil.copy(str(video_path), str(output_path))
            return True

        parts = probe_result.stdout.strip().split(",")
        width, height = int(parts[0]), int(parts[1])
        fps = eval(parts[2]) if "/" in parts[2] else float(parts[2])

        # ì›ë³¸ ì˜ìƒ ì˜¤ë””ì˜¤ ì •ë³´
        audio_probe_cmd = [
            "ffprobe", "-v", "error",
            "-select_streams", "a:0",
            "-show_entries", "stream=sample_rate,channels",
            "-of", "csv=p=0",
            str(video_path)
        ]
        audio_probe = subprocess.run(audio_probe_cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')

        sample_rate = 48000
        channels = 2
        channel_layout = "stereo"

        if audio_probe.returncode == 0 and audio_probe.stdout.strip():
            audio_parts = audio_probe.stdout.strip().split(",")
            if len(audio_parts) >= 2:
                try:
                    sample_rate = int(audio_parts[0])
                    channels = int(audio_parts[1])
                    channel_layout = "stereo" if channels >= 2 else "mono"
                    self.log(f"  ğŸ”Š ì›ë³¸ ì˜¤ë””ì˜¤: {sample_rate}Hz, {channels}ch")
                except:
                    pass

        videos_to_concat = []

        # ì˜¤í”„ë‹ ì´ë¯¸ì§€ -> ì˜ìƒ ë³€í™˜
        if opening_image and Path(opening_image).exists():
            opening_video = self.temp_dir / "opening_temp.mp4"
            cmd = [
                "ffmpeg", "-y",
                "-loop", "1",
                "-i", str(opening_image),
                "-f", "lavfi", "-i", f"anullsrc=channel_layout={channel_layout}:sample_rate={sample_rate}",
                "-t", str(duration),
                "-vf", f"scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2,fade=t=out:st={duration-fade_duration}:d={fade_duration}",
            ] + encoder_args + [
                "-c:a", "aac", "-b:a", "192k",
                "-shortest",
                "-r", str(fps),
                str(opening_video)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
            if result.returncode == 0:
                videos_to_concat.append(str(opening_video))
                self.log(f"  âœ“ ì˜¤í”„ë‹ ìƒì„± ({duration}ì´ˆ)")

        # ë©”ì¸ ì˜ìƒ (í˜ì´ë“œ ì¸/ì•„ì›ƒ ì ìš©)
        main_video = video_path
        if opening_image or closing_image:
            duration_cmd = [
                "ffprobe", "-v", "error",
                "-show_entries", "format=duration",
                "-of", "csv=p=0",
                str(video_path)
            ]
            dur_result = subprocess.run(duration_cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
            main_duration = float(dur_result.stdout.strip())

            fade_filters = []
            if opening_image and Path(opening_image).exists():
                fade_filters.append(f"fade=t=in:st=0:d={fade_duration}")
            if closing_image and Path(closing_image).exists():
                fade_filters.append(f"fade=t=out:st={main_duration-fade_duration}:d={fade_duration}")

            if fade_filters:
                main_faded = self.temp_dir / "main_faded.mp4"
                cmd = [
                    "ffmpeg", "-y",
                    "-i", str(video_path),
                    "-vf", ",".join(fade_filters),
                ] + encoder_args + [
                    "-c:a", "copy",
                    str(main_faded)
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
                if result.returncode == 0:
                    main_video = main_faded

        videos_to_concat.append(str(main_video))

        # í´ë¡œì§• ì´ë¯¸ì§€ -> ì˜ìƒ ë³€í™˜
        if closing_image and Path(closing_image).exists():
            closing_video = self.temp_dir / "closing_temp.mp4"
            cmd = [
                "ffmpeg", "-y",
                "-loop", "1",
                "-i", str(closing_image),
                "-f", "lavfi", "-i", f"anullsrc=channel_layout={channel_layout}:sample_rate={sample_rate}",
                "-t", str(duration),
                "-vf", f"scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2,fade=t=in:st=0:d={fade_duration}",
            ] + encoder_args + [
                "-c:a", "aac", "-b:a", "192k",
                "-shortest",
                "-r", str(fps),
                str(closing_video)
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
            if result.returncode == 0:
                videos_to_concat.append(str(closing_video))
                self.log(f"  âœ“ í´ë¡œì§• ìƒì„± ({duration}ì´ˆ)")

        # concat
        if len(videos_to_concat) == 1:
            shutil.copy(str(main_video), str(output_path))
            return True

        concat_file = self.temp_dir / "concat_list.txt"
        with open(concat_file, "w", encoding="utf-8") as f:
            for v in videos_to_concat:
                f.write(f"file '{v}'\n")

        cmd = [
            "ffmpeg", "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", str(concat_file),
        ] + encoder_args + [
            "-c:a", "copy",
            "-movflags", "+faststart",
            str(output_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        return result.returncode == 0

    def run(self, input_video, output_path=None, upscale=None, opening=None, closing=None, skip_default_openclose=False):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        input_path = Path(input_video)
        if not input_path.exists():
            self.log(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_video}")
            return False

        if output_path is None:
            output_path = config.OUTPUT_DIR / f"{input_path.stem}_subtitled.mp4"
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        self.log("=" * 60)
        self.log("ğŸ¬ ìë§‰ ëª¨ë“œ CLI ì‹œì‘")
        self.log("=" * 60)

        # Step 0: íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë ¬
        self.log("\nâ±ï¸ Step 0: íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë ¬...")
        normalized_video = self.temp_dir / "normalized.mp4"
        cmd = [
            "ffmpeg", "-y",
            "-i", str(input_path),
            "-map", "0", "-c", "copy",
            "-avoid_negative_ts", "make_zero",
            str(normalized_video)
        ]
        subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
        working_video = normalized_video if normalized_video.exists() else input_path
        self.log("  âœ“ ì™„ë£Œ")

        # Step 1: ì˜¤ë””ì˜¤ ì¶”ì¶œ
        self.log("\nğŸµ Step 1: ì˜¤ë””ì˜¤ ì¶”ì¶œ...")
        audio_path = self.temp_dir / "audio.wav"
        if not self.extract_audio_from_video(working_video, audio_path):
            self.log("âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨")
            return False
        self.log("  âœ“ ì™„ë£Œ")

        # Step 2: Whisper STT
        self.log("\nğŸ¤ Step 2: ìŒì„± ì¸ì‹ (Whisper)...")
        transcript = self.transcribe_with_whisper(audio_path)
        segments = []
        if hasattr(transcript, 'segments'):
            for seg in transcript.segments:
                if isinstance(seg, dict):
                    segments.append(seg)
                else:
                    segments.append({
                        "start": seg.start,
                        "end": seg.end,
                        "text": seg.text
                    })
        for seg in segments:
            seg["corrected_text"] = seg.get("text", "")

        # Step 3: ìë§‰ í¬ë§·íŒ…
        self.log("\nğŸ“ Step 3: ìë§‰ í¬ë§·íŒ…...")
        formatted = self.format_subtitles(segments)
        ass_path = self.temp_dir / "subtitles.ass"
        self.generate_ass_subtitles(formatted, ass_path)
        self.log(f"  âœ“ {len(formatted)}ê°œ ìë§‰ ìƒì„±")

        # Step 4: í¬ë¡­
        self.log("\nâœ‚ï¸ Step 4: í¬ë¡­ ë° ìŠ¤ì¼€ì¼...")
        cropped_path = self.temp_dir / "cropped.mp4"
        renderer = FFmpegRenderer()
        renderer.crop_and_scale_video(working_video, cropped_path)
        video_for_subtitle = cropped_path if cropped_path.exists() else working_video
        self.log("  âœ“ ì™„ë£Œ")

        # Step 5: ìë§‰ í•©ì„±
        self.log("\nğŸ¬ Step 5: ìë§‰ í•©ì„±...")
        subtitled_path = self.temp_dir / "subtitled.mp4"
        if not self.burn_subtitles(video_for_subtitle, ass_path, subtitled_path):
            self.log("âŒ ìë§‰ í•©ì„± ì‹¤íŒ¨")
            return False
        self.log("  âœ“ ì™„ë£Œ")

        final_video = subtitled_path

        # Step 6: ì—…ìŠ¤ì¼€ì¼ (ì„ íƒ)
        if upscale:
            self.log(f"\nğŸ“ˆ Step 6: ì—…ìŠ¤ì¼€ì¼ ({upscale}p)...")
            upscaled_path = self.temp_dir / "upscaled.mp4"
            self.upscale_video(final_video, upscaled_path, upscale)
            if upscaled_path.exists():
                final_video = upscaled_path
            self.log("  âœ“ ì™„ë£Œ")

        # Step 7: ì˜¤í”„ë‹/í´ë¡œì§• (ê¸°ë³¸ ì´ë¯¸ì§€ ìë™ ì‚¬ìš©)
        opening_img = opening
        closing_img = closing

        # ì¸ìë¡œ ì•ˆ ì¤¬ìœ¼ë©´ ê¸°ë³¸ ì´ë¯¸ì§€ í™•ì¸ (skip_default_opencloseê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
        if not skip_default_openclose:
            if not opening_img and self.DEFAULT_OPENING.exists():
                opening_img = str(self.DEFAULT_OPENING)
            if not closing_img and self.DEFAULT_CLOSING.exists():
                closing_img = str(self.DEFAULT_CLOSING)

        if opening_img or closing_img:
            self.log("\nğŸ¬ Step 7: ì˜¤í”„ë‹/í´ë¡œì§• ì¶”ê°€...")
            if opening_img:
                self.log(f"  ğŸ“¸ ì˜¤í”„ë‹: {Path(opening_img).name}")
            if closing_img:
                self.log(f"  ğŸ“¸ í´ë¡œì§•: {Path(closing_img).name}")

            with_openclose = self.temp_dir / "with_openclose.mp4"
            if self.add_opening_closing(final_video, with_openclose, opening_img, closing_img):
                final_video = with_openclose
                self.log("  âœ“ ì™„ë£Œ")
            else:
                self.log("  âš ï¸ ì˜¤í”„ë‹/í´ë¡œì§• ì¶”ê°€ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©")

        # ìµœì¢… ë³µì‚¬
        shutil.copy(final_video, output_path)

        self.log("\n" + "=" * 60)
        self.log("âœ… ì™„ë£Œ!")
        self.log(f"ğŸ“ ì¶œë ¥: {output_path}")
        self.log("=" * 60)

        return True


def main():
    parser = argparse.ArgumentParser(
        description="ìë§‰ ëª¨ë“œ CLI - MP4 + Whisper STT + ìë§‰ í•©ì„±",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  python subtitle_cli.py video.mp4
  python subtitle_cli.py video.mp4 --output result.mp4
  python subtitle_cli.py video.mp4 --upscale 1080
  python subtitle_cli.py video.mp4 --opening intro.png --closing outro.png

ê¸°ë³¸ ì˜¤í”„ë‹/í´ë¡œì§•:
  assets/opening.png, assets/closing.png íŒŒì¼ì´ ìˆìœ¼ë©´ ìë™ ì‚¬ìš©
        """
    )

    parser.add_argument("input", help="ì…ë ¥ MP4 íŒŒì¼")
    parser.add_argument("-o", "--output", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--upscale", type=int, help="ì—…ìŠ¤ì¼€ì¼ í•´ìƒë„ (ì˜ˆ: 1080)")
    parser.add_argument("--opening", help="ì˜¤í”„ë‹ ì´ë¯¸ì§€ (ê¸°ë³¸: assets/opening.png)")
    parser.add_argument("--closing", help="í´ë¡œì§• ì´ë¯¸ì§€ (ê¸°ë³¸: assets/closing.png)")
    parser.add_argument("--no-openclose", action="store_true", help="ì˜¤í”„ë‹/í´ë¡œì§• ë¹„í™œì„±í™”")

    args = parser.parse_args()

    # --no-opencloseë©´ ì˜¤í”„ë‹/í´ë¡œì§• ë¹„í™œì„±í™”
    opening = None if args.no_openclose else args.opening
    closing = None if args.no_openclose else args.closing

    cli = SubtitleCLI()
    success = cli.run(
        args.input,
        args.output,
        args.upscale,
        opening,
        closing,
        skip_default_openclose=args.no_openclose
    )

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
