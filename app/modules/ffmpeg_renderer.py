"""
ëª¨ë“ˆ F: FFmpeg ë Œë”ëŸ¬
ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ë¥¼ ì˜ìƒìœ¼ë¡œ ì¡°ë¦½
"""
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import subprocess
import os
import shutil
from concurrent.futures import ThreadPoolExecutor, as_completed
from .font_utils import get_font_path_with_fallback


class FFmpegRenderer:
    """FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¬ë¼ì´ë“œë¥¼ ì˜ìƒìœ¼ë¡œ ë Œë”ë§í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(
        self,
        width: int = 1920,
        height: int = 1080,
        fps: int = 30,
        preset: str = "medium",
        crf: int = 23
    ):
        """
        Args:
            width: ì˜ìƒ ë„ˆë¹„
            height: ì˜ìƒ ë†’ì´
            fps: í”„ë ˆì„ ë ˆì´íŠ¸
            preset: FFmpeg preset (ultrafast, fast, medium, slow)
            crf: í’ˆì§ˆ ì„¤ì • (0-51, ë‚®ì„ìˆ˜ë¡ ê³ í’ˆì§ˆ)
        """
        self.width = width
        self.height = height
        self.fps = fps
        self.preset = preset
        self.crf = crf

    def create_slide_clip(
        self,
        image_path: Path,
        audio_path: Path,
        duration: float,
        output_path: Path,
        keyword_overlays: Optional[List[Dict[str, Any]]] = None,
        enable_keyword_marking: bool = False,
        highlight: Optional[Dict[str, Any]] = None,
        arrow_pointers: Optional[List[Dict[str, Any]]] = None
    ) -> bool:
        """
        ë‹¨ì¼ ìŠ¬ë¼ì´ë“œ í´ë¦½ ìƒì„± (ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + í‚¤ì›Œë“œ ë§ˆí‚¹ ì˜¤ë²„ë ˆì´ + í•˜ì´ë¼ì´íŠ¸ + í™”ì‚´í‘œ)

        Args:
            image_path: ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ê²½ë¡œ
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            duration: ì˜ìƒ ê¸¸ì´ (ì´ˆ)
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ
            keyword_overlays: í‚¤ì›Œë“œ ì˜¤ë²„ë ˆì´ ë¦¬ìŠ¤íŠ¸ [{"overlay_image": "path", "timing": 2.5, "found": True}, ...]
            enable_keyword_marking: í‚¤ì›Œë“œ ë§ˆí‚¹ ì‚¬ìš© ì—¬ë¶€
            highlight: í•µì‹¬ ë¬¸êµ¬ í•˜ì´ë¼ì´íŠ¸ {"text": "ê°•ì¡°ë¬¸êµ¬", "timing": 5.0}
            arrow_pointers: í™”ì‚´í‘œ í¬ì¸í„° ë¦¬ìŠ¤íŠ¸ [{"target_x": 100, "target_y": 200, "timing": 3.0}, ...]

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ê¸°ë³¸ FFmpeg ëª…ë ¹ ì‹œì‘
            cmd = [
                "ffmpeg",
                "-y",  # ë®ì–´ì“°ê¸°
                "-loop", "1",  # ì´ë¯¸ì§€ ë£¨í”„
                "-i", str(image_path),  # ì…ë ¥ ì´ë¯¸ì§€ (input 0)
            ]

            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì…ë ¥ ì¶”ê°€
            overlay_inputs = []
            if enable_keyword_marking and keyword_overlays:
                print(f"ğŸ” í‚¤ì›Œë“œ ì˜¤ë²„ë ˆì´ ì²˜ë¦¬ ì‹œì‘ ({len(keyword_overlays)}ê°œ)")
                for idx, overlay_info in enumerate(keyword_overlays):
                    print(f"  [{idx}] ê²€ì‚¬: {overlay_info.get('keyword', 'Unknown')}")
                    print(f"      - found: {overlay_info.get('found')}")
                    print(f"      - overlay_image: {overlay_info.get('overlay_image')}")

                    if overlay_info.get("found") and overlay_info.get("overlay_image"):
                        overlay_path = overlay_info["overlay_image"]
                        path_exists = Path(overlay_path).exists()
                        print(f"      - íŒŒì¼ ì¡´ì¬: {path_exists}")

                        if path_exists:
                            cmd.extend(["-loop", "1", "-i", str(overlay_path)])
                            overlay_inputs.append(overlay_info)
                            print(f"      âœ“ ì˜¤ë²„ë ˆì´ ì¶”ê°€ë¨")
                        else:
                            print(f"      âœ— íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {overlay_path}")
                    else:
                        print(f"      âœ— ìŠ¤í‚µ (found={overlay_info.get('found')}, has_image={bool(overlay_info.get('overlay_image'))})")

                print(f"ğŸ” ìµœì¢… ì˜¤ë²„ë ˆì´ ê°œìˆ˜: {len(overlay_inputs)}ê°œ")
            else:
                if not enable_keyword_marking:
                    print("ğŸ” í‚¤ì›Œë“œ ë§ˆí‚¹ ë¹„í™œì„±í™”ë¨")
                elif not keyword_overlays:
                    print("ğŸ” í‚¤ì›Œë“œ ì˜¤ë²„ë ˆì´ ë°ì´í„° ì—†ìŒ")

            # í™”ì‚´í‘œ í¬ì¸í„° ì´ë¯¸ì§€ ì…ë ¥ ì¶”ê°€
            arrow_inputs = []
            if arrow_pointers:
                # í™”ì‚´í‘œ PNG ê²½ë¡œ
                arrow_png = Path(__file__).parent.parent / "assets" / "arrow_pointer.png"
                if arrow_png.exists():
                    for arrow_info in arrow_pointers:
                        cmd.extend(["-loop", "1", "-i", str(arrow_png)])
                        arrow_inputs.append(arrow_info)
                        print(f"    ğŸ¹ í™”ì‚´í‘œ ì¶”ê°€: {arrow_info.get('keyword', '')} @{arrow_info.get('timing', 0):.1f}ì´ˆ")
                else:
                    print(f"    âš ï¸ í™”ì‚´í‘œ ì´ë¯¸ì§€ ì—†ìŒ: {arrow_png}")

            # ì˜¤ë””ì˜¤ ì…ë ¥
            cmd.extend(["-i", str(audio_path)])  # ë§ˆì§€ë§‰ ì…ë ¥ì€ ì˜¤ë””ì˜¤

            # í•„í„° ë³µì¡ì„± êµ¬ì„±
            has_overlay = bool(overlay_inputs)
            has_highlight = bool(highlight and highlight.get("text"))
            has_arrow = bool(arrow_inputs)

            if has_overlay or has_highlight or has_arrow:
                # ë³µí•© í•„í„° êµ¬ì„±
                filter_complex = f"[0:v]format=yuv420p[base]"
                prev_label = "base"
                final_label = "out"

                # í‚¤ì›Œë“œ ì˜¤ë²„ë ˆì´ í•„í„° ì¶”ê°€
                if has_overlay:
                    for i, overlay_info in enumerate(overlay_inputs):
                        timing = overlay_info.get("timing", 0)
                        keyword = overlay_info.get("keyword", "Unknown")

                        # ì• ë‹ˆë©”ì´ì…˜ íƒ€ì´ë°
                        fade_in_start = max(0, timing - 0.5)
                        fade_in_end = timing
                        fade_out_start = timing + 2.0
                        fade_out_end = timing + 2.5

                        print(f"    ğŸ¬ '{keyword}': {fade_in_start:.1f}ì´ˆ í˜ì´ë“œì¸ â†’ {timing:.1f}ì´ˆ ì™„ì „í‘œì‹œ â†’ {fade_out_start:.1f}ì´ˆ ìœ ì§€ â†’ {fade_out_end:.1f}ì´ˆ í˜ì´ë“œì•„ì›ƒ")

                        # ì˜¤ë²„ë ˆì´ ì…ë ¥ ì¸ë±ìŠ¤ (input 0ì€ base ì´ë¯¸ì§€, input 1ë¶€í„° ì˜¤ë²„ë ˆì´)
                        overlay_idx = i + 1

                        # ì¶œë ¥ ë ˆì´ë¸”
                        is_last_overlay = (i == len(overlay_inputs) - 1)
                        if is_last_overlay and not has_arrow and not has_highlight:
                            out_label = "out"
                        else:
                            out_label = f"tmp{i}"

                        # overlay í•„í„° ì¶”ê°€
                        filter_complex += f";[{prev_label}][{overlay_idx}:v]overlay=enable='between(t,{fade_in_start},{fade_out_end})':format=auto:eval=frame,format=yuv420p[{out_label}]"
                        prev_label = out_label

                # í™”ì‚´í‘œ í¬ì¸í„° ì˜¤ë²„ë ˆì´ í•„í„° ì¶”ê°€
                if has_arrow:
                    # í™”ì‚´í‘œ ì…ë ¥ ì‹œì‘ ì¸ë±ìŠ¤ = 1 + í‚¤ì›Œë“œì˜¤ë²„ë ˆì´ ìˆ˜
                    arrow_start_idx = 1 + len(overlay_inputs)

                    for i, arrow_info in enumerate(arrow_inputs):
                        timing = arrow_info.get("timing", 0)
                        target_x = arrow_info.get("target_x", 0)
                        target_y = arrow_info.get("target_y", 0)
                        keyword = arrow_info.get("keyword", "")

                        # ì• ë‹ˆë©”ì´ì…˜ íƒ€ì´ë° (2ì´ˆê°„ í‘œì‹œ)
                        fade_in_start = max(0, timing - 0.3)
                        fade_out_end = timing + 2.0

                        # í™”ì‚´í‘œ ìœ„ì¹˜ ê³„ì‚°
                        # í™”ì‚´í‘œ ì´ë¯¸ì§€ëŠ” 200x200, ëì (tip)ì´ (40, 160)
                        # ë”°ë¼ì„œ ì˜¤ë²„ë ˆì´ ìœ„ì¹˜: x = target_x - 40, y = target_y - 160
                        arrow_x = max(0, target_x - 40)
                        arrow_y = max(0, target_y - 160)

                        print(f"    ğŸ¹ '{keyword}': {fade_in_start:.1f}ì´ˆ ~ {fade_out_end:.1f}ì´ˆ (ìœ„ì¹˜: {arrow_x}, {arrow_y})")

                        # í™”ì‚´í‘œ ì…ë ¥ ì¸ë±ìŠ¤
                        arrow_idx = arrow_start_idx + i

                        # ì¶œë ¥ ë ˆì´ë¸”
                        is_last_arrow = (i == len(arrow_inputs) - 1)
                        if is_last_arrow and not has_highlight:
                            out_label = "out"
                        else:
                            out_label = f"arrow{i}"

                        # overlay í•„í„° ì¶”ê°€ (ìœ„ì¹˜ ì§€ì • + í˜ì´ë“œ)
                        filter_complex += f";[{prev_label}][{arrow_idx}:v]overlay=x={arrow_x}:y={arrow_y}:enable='between(t,{fade_in_start},{fade_out_end})':format=auto:eval=frame,format=yuv420p[{out_label}]"
                        prev_label = out_label

                # í•˜ì´ë¼ì´íŠ¸ í…ìŠ¤íŠ¸ í•„í„° ì¶”ê°€ (í™”ë©´ ì¤‘ì•™ì— í¬ê²Œ í‘œì‹œ)
                if has_highlight:
                    hl_text = highlight["text"]
                    hl_timing = highlight.get("timing", 3.0)
                    hl_duration = 2.5  # í•˜ì´ë¼ì´íŠ¸ í‘œì‹œ ì‹œê°„

                    # íƒ€ì´ë° ê³„ì‚°
                    hl_start = max(0, hl_timing - 0.3)
                    hl_end = hl_timing + hl_duration

                    # í°íŠ¸ ê²½ë¡œ (Windows/Linux í˜¸í™˜)
                    font_path = get_font_path_with_fallback()
                    # ê²½ë¡œì—ì„œ ì—­ìŠ¬ë˜ì‹œë¥¼ ìŠ¬ë˜ì‹œë¡œ ë³€í™˜ (FFmpeg í˜¸í™˜)
                    font_path_escaped = str(font_path).replace('\\', '/').replace(':', '\\:')

                    # í…ìŠ¤íŠ¸ ì´ìŠ¤ì¼€ì´í”„ (íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
                    hl_text_escaped = hl_text.replace("'", "\\'").replace(":", "\\:")

                    # í˜ì´ë“œ ì¸/ì•„ì›ƒ + ìŠ¤ì¼€ì¼ ì• ë‹ˆë©”ì´ì…˜ í‘œí˜„ì‹
                    # alpha: 0 â†’ 1 â†’ 1 â†’ 0
                    alpha_expr = f"if(lt(t,{hl_start}),0,if(lt(t,{hl_start + 0.3}),(t-{hl_start})/0.3,if(lt(t,{hl_end - 0.3}),1,({hl_end}-t)/0.3)))"

                    print(f"    ğŸŒŸ í•˜ì´ë¼ì´íŠ¸ '{hl_text}': {hl_start:.1f}ì´ˆ ~ {hl_end:.1f}ì´ˆ (í™”ë©´ ì¤‘ì•™)")

                    # drawtext í•„í„° ì¶”ê°€
                    drawtext_filter = (
                        f"drawtext=fontfile='{font_path_escaped}'"
                        f":text='{hl_text_escaped}'"
                        f":fontsize=72"
                        f":fontcolor=white"
                        f":borderw=4"
                        f":bordercolor=black"
                        f":x=(w-text_w)/2"
                        f":y=(h-text_h)/2"
                        f":alpha='{alpha_expr}'"
                        f":enable='between(t,{hl_start},{hl_end})'"
                    )

                    filter_complex += f";[{prev_label}]{drawtext_filter}[out]"

                # filter_complex ì¶”ê°€
                cmd.extend(["-filter_complex", filter_complex])
                cmd.extend(["-map", "[out]"])  # ë¹„ë””ì˜¤ ì¶œë ¥ ë§¤í•‘
                # ì˜¤ë””ì˜¤ ì…ë ¥ ì¸ë±ìŠ¤ = 1 + í‚¤ì›Œë“œì˜¤ë²„ë ˆì´ ìˆ˜ + í™”ì‚´í‘œ ìˆ˜
                audio_input_idx = 1 + len(overlay_inputs) + len(arrow_inputs)
                cmd.extend(["-map", f"{audio_input_idx}:a"])  # ì˜¤ë””ì˜¤ ì¶œë ¥ ë§¤í•‘
            else:
                # ì˜¤ë²„ë ˆì´/í•˜ì´ë¼ì´íŠ¸ ì—†ìŒ: í¬ë§· ë³€í™˜ë§Œ ìˆ˜í–‰
                cmd.extend(["-vf", "format=yuv420p"])

            # ê³µí†µ ì¸ì½”ë”© ì˜µì…˜
            cmd.extend([
                "-c:v", "libx264",  # ë¹„ë””ì˜¤ ì½”ë±
                "-preset", self.preset,  # ì¸ì½”ë”© ì†ë„
                "-crf", str(self.crf),  # í’ˆì§ˆ
                "-c:a", "aac",  # ì˜¤ë””ì˜¤ ì½”ë±
                "-b:a", "192k",  # ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸
                "-ar", "44100",  # ìƒ˜í”Œë ˆì´íŠ¸
                "-pix_fmt", "yuv420p",  # í”½ì…€ í¬ë§·
                "-t", str(duration),  # ì˜ìƒ ê¸¸ì´
                "-shortest",  # ì§§ì€ ì…ë ¥ì— ë§ì¶¤
                str(output_path)
            ])

            # ë””ë²„ê·¸: FFmpeg ëª…ë ¹ì–´ ì¶œë ¥
            if overlay_inputs:
                print(f"\nğŸ” FFmpeg ë””ë²„ê·¸ (í‚¤ì›Œë“œ ë§ˆí‚¹ {len(overlay_inputs)}ê°œ):")
                overlay_files = [Path(oi['overlay_image']).name for oi in overlay_inputs]
                timings = [f"{oi['timing']:.1f}ì´ˆ" for oi in overlay_inputs]
                print(f"  - ì˜¤ë²„ë ˆì´ íŒŒì¼: {overlay_files}")
                print(f"  - íƒ€ì´ë°: {timings}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            if result.stderr and "error" in result.stderr.lower():
                print(f"âš ï¸  FFmpeg ê²½ê³ : {result.stderr[:500]}")

            return True

        except subprocess.CalledProcessError as e:
            print(f"âœ— FFmpeg ì—ëŸ¬: {e.stderr}")
            return False

    def concatenate_clips(
        self,
        clip_paths: List[Path],
        output_path: Path
    ) -> bool:
        """
        ì—¬ëŸ¬ í´ë¦½ì„ í•˜ë‚˜ì˜ ì˜ìƒìœ¼ë¡œ ì—°ê²° (ì „í™˜ íš¨ê³¼ ì—†ìŒ)

        Args:
            clip_paths: í´ë¦½ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        # concat íŒŒì¼ ìƒì„±
        concat_file = output_path.parent / "concat_list.txt"

        with open(concat_file, 'w') as f:
            for clip_path in clip_paths:
                f.write(f"file '{clip_path.absolute()}'\n")

        try:
            cmd = [
                "ffmpeg",
                "-y",
                "-f", "concat",
                "-safe", "0",
                "-i", str(concat_file),
                "-c", "copy",
                str(output_path)
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            # concat íŒŒì¼ ì‚­ì œ
            concat_file.unlink()

            return True

        except subprocess.CalledProcessError as e:
            print(f"âœ— FFmpeg concat ì—ëŸ¬: {e.stderr}")
            return False

    def get_video_duration(self, video_path: Path) -> float:
        """ì˜ìƒ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸° (ì´ˆ)"""
        try:
            cmd = [
                "ffprobe",
                "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(video_path)
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            return float(result.stdout.strip())

        except Exception:
            return 0.0

    def concatenate_clips_with_transition(
        self,
        clip_paths: List[Path],
        output_path: Path,
        transition: str = "fade",
        duration: float = 0.5
    ) -> bool:
        """
        ì—¬ëŸ¬ í´ë¦½ì„ ì „í™˜ íš¨ê³¼ì™€ í•¨ê»˜ í•˜ë‚˜ì˜ ì˜ìƒìœ¼ë¡œ ì—°ê²°

        Args:
            clip_paths: í´ë¦½ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ
            transition: ì „í™˜ íš¨ê³¼ ("fade", "dissolve", "slide", "wipe")
            duration: ì „í™˜ íš¨ê³¼ ê¸¸ì´ (ì´ˆ)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        if len(clip_paths) < 2:
            # í´ë¦½ì´ 1ê°œë©´ ì „í™˜ íš¨ê³¼ ì—†ì´ ë³µì‚¬
            return self.concatenate_clips(clip_paths, output_path)

        try:
            # xfade íš¨ê³¼ ë§¤í•‘
            xfade_map = {
                "fade": "fade",
                "dissolve": "dissolve",
                "slide": "slideleft",
                "wipe": "wipeleft"
            }
            xfade_effect = xfade_map.get(transition, "fade")

            # ê° í´ë¦½ì˜ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
            clip_durations = []
            for clip_path in clip_paths:
                clip_duration = self.get_video_duration(clip_path)
                clip_durations.append(clip_duration)

            # FFmpeg ëª…ë ¹ êµ¬ì„±
            cmd = ["ffmpeg", "-y"]

            # ëª¨ë“  í´ë¦½ ì…ë ¥
            for clip_path in clip_paths:
                cmd.extend(["-i", str(clip_path)])

            # filter_complex êµ¬ì„±
            filter_parts = []
            prev_label = "[0:v]"
            offset = 0.0

            for i in range(len(clip_paths) - 1):
                curr_label = f"[v{i}]" if i < len(clip_paths) - 2 else "[outv]"
                next_input = f"[{i+1}:v]"

                # offset ê³„ì‚°: ì´ì „ í´ë¦½ë“¤ì˜ ê¸¸ì´ í•© - ì „í™˜ íš¨ê³¼ ê¸¸ì´ * ì¸ë±ìŠ¤
                if i == 0:
                    offset = clip_durations[0] - duration
                else:
                    offset += clip_durations[i] - duration

                # xfade í•„í„° ì¶”ê°€
                filter_parts.append(
                    f"{prev_label}{next_input}xfade=transition={xfade_effect}:duration={duration}:offset={offset:.2f}{curr_label}"
                )
                prev_label = curr_label

            # ì˜¤ë””ì˜¤ ì—°ê²°
            audio_inputs = "".join(f"[{i}:a]" for i in range(len(clip_paths)))
            filter_parts.append(f"{audio_inputs}concat=n={len(clip_paths)}:v=0:a=1[outa]")

            filter_complex = ";".join(filter_parts)

            cmd.extend([
                "-filter_complex", filter_complex,
                "-map", "[outv]",
                "-map", "[outa]",
                "-c:v", "libx264",
                "-preset", self.preset,
                "-crf", str(self.crf),
                "-c:a", "aac",
                str(output_path)
            ])

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            return True

        except subprocess.CalledProcessError as e:
            print(f"âœ— FFmpeg xfade ì—ëŸ¬: {e.stderr}")
            print(f"  â†’ ì „í™˜ íš¨ê³¼ ì—†ì´ ì¬ì‹œë„...")
            # ì‹¤íŒ¨ ì‹œ ì „í™˜ íš¨ê³¼ ì—†ì´ ì¬ì‹œë„
            return self.concatenate_clips(clip_paths, output_path)

    def burn_subtitles(self, input_video: Path, subtitle_file: Path, output_video: Path, font_size: int = 18) -> bool:
        """
        ë¹„ë””ì˜¤ì— SRT ìë§‰ì„ ë²ˆì¸(burn-in)

        Args:
            input_video: ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼
            subtitle_file: SRT ìë§‰ íŒŒì¼
            output_video: ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼
            font_size: ìë§‰ í°íŠ¸ í¬ê¸° (ê¸°ë³¸ê°’: 18)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # Windows ê²½ë¡œ ì´ìŠ¤ì¼€ì´í•‘ ë¬¸ì œ í•´ê²°: ìë§‰ íŒŒì¼ì„ ë¹„ë””ì˜¤ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
            temp_subtitle = input_video.parent / "temp_subtitle.srt"
            shutil.copy(str(subtitle_file), str(temp_subtitle))

            # ë°©ë²• 1: force_styleë¡œ í•œê¸€ í°íŠ¸ ì§€ì •
            cmd = [
                "ffmpeg",
                "-i", str(input_video),
                "-vf", f"subtitles={temp_subtitle.name}:force_style='FontName=Malgun Gothic,FontSize={font_size},PrimaryColour=&HFFFFFF&,OutlineColour=&H000000&,BorderStyle=3,Outline=2,Shadow=1,MarginV=30'",
                "-c:a", "copy",  # ì˜¤ë””ì˜¤ëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬
                "-y",
                str(output_video)
            ]

            try:
                # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë¹„ë””ì˜¤ íŒŒì¼ ìœ„ì¹˜ë¡œ ë³€ê²½
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    check=True,
                    cwd=str(input_video.parent)
                )
                # ì„ì‹œ ìë§‰ íŒŒì¼ ì‚­ì œ
                if temp_subtitle.exists():
                    temp_subtitle.unlink()
                return True

            except subprocess.CalledProcessError as e:
                print(f"  âš ï¸  force_style ì‹¤íŒ¨, ê¸°ë³¸ ìŠ¤íƒ€ì¼ë¡œ ì¬ì‹œë„...")

                # ë°©ë²• 2: force_style ì—†ì´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
                cmd_simple = [
                    "ffmpeg",
                    "-i", str(input_video),
                    "-vf", f"subtitles={temp_subtitle.name}",
                    "-c:a", "copy",
                    "-y",
                    str(output_video)
                ]

                result = subprocess.run(
                    cmd_simple,
                    capture_output=True,
                    text=True,
                    check=True,
                    cwd=str(input_video.parent)
                )
                # ì„ì‹œ ìë§‰ íŒŒì¼ ì‚­ì œ
                if temp_subtitle.exists():
                    temp_subtitle.unlink()
                return True

        except subprocess.CalledProcessError as e:
            print(f"âœ— ìë§‰ ë²ˆì¸ ì—ëŸ¬: {e.stderr}")
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'temp_subtitle' in locals() and temp_subtitle.exists():
                temp_subtitle.unlink()
            return False
        except Exception as e:
            print(f"âœ— ìë§‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'temp_subtitle' in locals() and temp_subtitle.exists():
                temp_subtitle.unlink()
            return False

    def _render_single_clip(
        self,
        slide: Dict,
        audio_info: Dict,
        slides_img_dir: Path,
        audio_dir: Path,
        clips_dir: Path,
        scripts_data: Dict,
        enable_keyword_marking: bool
    ) -> Optional[Path]:
        """
        ë‹¨ì¼ ìŠ¬ë¼ì´ë“œ í´ë¦½ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ìš© í—¬í¼ í•¨ìˆ˜)

        Args:
            slide: ìŠ¬ë¼ì´ë“œ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            audio_info: ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„°
            slides_img_dir: ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            audio_dir: ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬
            clips_dir: í´ë¦½ ì¶œë ¥ ë””ë ‰í† ë¦¬
            scripts_data: ëŒ€ë³¸ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            enable_keyword_marking: í‚¤ì›Œë“œ ë§ˆí‚¹ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ìƒì„±ëœ í´ë¦½ ê²½ë¡œ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        index = slide["index"]

        # íŒŒì¼ ê²½ë¡œ
        image_path = slides_img_dir / f"slide_{index:03d}.png"
        audio_path = audio_dir / f"slide_{index:03d}.mp3"
        clip_path = clips_dir / f"clip_{index:03d}.mp4"

        # ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not image_path.exists():
            print(f"  âš  ìŠ¬ë¼ì´ë“œ {index}: ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ ({image_path})")
            return None

        # ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not audio_path.exists():
            print(f"  âš  ìŠ¬ë¼ì´ë“œ {index}: ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ ({audio_path})")
            return None

        print(f"  ìŠ¬ë¼ì´ë“œ {index}: í´ë¦½ ìƒì„± ì¤‘...")

        # í‚¤ì›Œë“œ ì˜¤ë²„ë ˆì´, í•˜ì´ë¼ì´íŠ¸, í™”ì‚´í‘œ í¬ì¸í„° ê°€ì ¸ì˜¤ê¸°
        keyword_overlays = []
        highlight = None
        arrow_pointers = []
        if index in scripts_data:
            if enable_keyword_marking:
                keyword_overlays = scripts_data[index].get("keyword_overlays", [])
                if keyword_overlays:
                    found_count = sum(1 for kw in keyword_overlays if kw.get("found"))
                    print(f"    â†’ í‚¤ì›Œë“œ ë§ˆí‚¹ {found_count}/{len(keyword_overlays)}ê°œ ì¶”ê°€")

            # í•˜ì´ë¼ì´íŠ¸ ê°€ì ¸ì˜¤ê¸°
            highlight = scripts_data[index].get("highlight")
            if highlight:
                print(f"    â†’ í•˜ì´ë¼ì´íŠ¸: ã€Œ{highlight.get('text', '')}ã€ @ {highlight.get('timing', 0):.1f}ì´ˆ")

            # í™”ì‚´í‘œ í¬ì¸í„° ê°€ì ¸ì˜¤ê¸°
            arrow_pointers = scripts_data[index].get("arrow_pointers", [])
            if arrow_pointers:
                print(f"    â†’ í™”ì‚´í‘œ í¬ì¸í„° {len(arrow_pointers)}ê°œ ì¶”ê°€")

        # í´ë¦½ ìƒì„±
        success = self.create_slide_clip(
            image_path,
            audio_path,
            audio_info["duration"],
            clip_path,
            keyword_overlays=keyword_overlays,
            enable_keyword_marking=enable_keyword_marking,
            highlight=highlight,
            arrow_pointers=arrow_pointers
        )

        if success:
            print(f"    âœ“ ì™„ë£Œ ({audio_info['duration']}ì´ˆ)")
            return clip_path
        else:
            print(f"    âœ— ì‹¤íŒ¨")
            return None

    def render_video(
        self,
        slides_json_path: Path,
        audio_meta_path: Path,
        slides_img_dir: Path,
        audio_dir: Path,
        clips_dir: Path,
        output_video_path: Path,
        scripts_json_path: Optional[Path] = None,
        enable_keyword_marking: bool = False,
        transition_effect: str = "fade",
        transition_duration: float = 0.5,
        subtitle_file: Optional[Path] = None,
        subtitle_font_size: int = 18,
        max_workers: int = 3
    ) -> bool:
        """
        ì „ì²´ ì˜ìƒ ë Œë”ë§ (ë³‘ë ¬ ì²˜ë¦¬)

        Args:
            slides_json_path: ìŠ¬ë¼ì´ë“œ ì •ë³´ JSON
            audio_meta_path: ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° JSON
            slides_img_dir: ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            audio_dir: ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬
            clips_dir: í´ë¦½ ì„ì‹œ ë””ë ‰í† ë¦¬
            output_video_path: ìµœì¢… ì¶œë ¥ ì˜ìƒ ê²½ë¡œ
            scripts_json_path: ëŒ€ë³¸ ì •ë³´ JSON (í‚¤ì›Œë“œ ì˜¤ë²„ë ˆì´ í¬í•¨)
            enable_keyword_marking: í‚¤ì›Œë“œ ë§ˆí‚¹ ì‚¬ìš© ì—¬ë¶€
            subtitle_file: ìë§‰ SRT íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
            transition_effect: ìŠ¬ë¼ì´ë“œ ì „í™˜ íš¨ê³¼ ("none", "fade", "dissolve", "slide", "wipe")
            transition_duration: ì „í™˜ íš¨ê³¼ ê¸¸ì´ (ì´ˆ)
            max_workers: ìµœëŒ€ ë³‘ë ¬ ì‘ì—… ìˆ˜ (ê¸°ë³¸ 3ê°œ, FFmpegëŠ” CPU ì§‘ì•½ì ì´ë¯€ë¡œ ë‚®ê²Œ ì„¤ì •)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        # ë°ì´í„° ë¡œë“œ
        with open(slides_json_path, 'r', encoding='utf-8') as f:
            slides = json.load(f)

        with open(audio_meta_path, 'r', encoding='utf-8') as f:
            audio_meta = json.load(f)

        # ëŒ€ë³¸ ë°ì´í„° ë¡œë“œ (í‚¤ì›Œë“œ ì˜¤ë²„ë ˆì´ í¬í•¨)
        scripts_data = {}
        if scripts_json_path and scripts_json_path.exists():
            with open(scripts_json_path, 'r', encoding='utf-8') as f:
                scripts_list = json.load(f)
                # indexë¡œ ë¹ ë¥´ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                scripts_data = {s["index"]: s for s in scripts_list}

        clips_dir.mkdir(parents=True, exist_ok=True)

        print(f"ì˜ìƒ ë Œë”ë§ ì‹œì‘: {len(slides)}ê°œ ìŠ¬ë¼ì´ë“œ (ë³‘ë ¬ ì²˜ë¦¬: {max_workers}ê°œ ë™ì‹œ)")

        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìŠ¬ë¼ì´ë“œë³„ í´ë¦½ ìƒì„±
        clip_results = []
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ëª¨ë“  ì‘ì—… ì œì¶œ
            future_to_slide = {}
            for i, slide in enumerate(slides):
                future = executor.submit(
                    self._render_single_clip,
                    slide,
                    audio_meta[i],
                    slides_img_dir,
                    audio_dir,
                    clips_dir,
                    scripts_data,
                    enable_keyword_marking
                )
                future_to_slide[future] = (i, slide)

            # ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(future_to_slide):
                i, slide = future_to_slide[future]
                try:
                    clip_path = future.result()
                    if clip_path:
                        clip_results.append((i, clip_path))
                except Exception as e:
                    print(f"    âœ— ìŠ¤ë ˆë“œ ì‹¤í–‰ ì˜¤ë¥˜ (ìŠ¬ë¼ì´ë“œ {slide['index']}): {e}")

        # index ìˆœì„œëŒ€ë¡œ ì •ë ¬
        clip_results.sort(key=lambda x: x[0])
        clip_paths = [clip_path for _, clip_path in clip_results]

        if not clip_paths:
            print("âœ— ìƒì„±ëœ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # í´ë¦½ ì—°ê²°
        print(f"\ní´ë¦½ ì—°ê²° ì¤‘: {len(clip_paths)}ê°œ í´ë¦½")

        if transition_effect != "none" and transition_duration > 0:
            print(f"  - ì „í™˜ íš¨ê³¼: {transition_effect} ({transition_duration}ì´ˆ)")
            success = self.concatenate_clips_with_transition(
                clip_paths, output_video_path, transition_effect, transition_duration
            )
        else:
            success = self.concatenate_clips(clip_paths, output_video_path)

        if success:
            # ìë§‰ ì¶”ê°€ (ì„ íƒì )
            if subtitle_file and subtitle_file.exists():
                print(f"\nìë§‰ ì¶”ê°€ ì¤‘: {subtitle_file.name}")
                temp_video = output_video_path.parent / f"{output_video_path.stem}_no_subs.mp4"

                try:
                    # ì›ë³¸ì„ ì„ì‹œ íŒŒì¼ë¡œ ì´ë™
                    shutil.move(str(output_video_path), str(temp_video))

                    subtitle_success = self.burn_subtitles(temp_video, subtitle_file, output_video_path, subtitle_font_size)

                    if subtitle_success:
                        print(f"  âœ“ ìë§‰ ì¶”ê°€ ì™„ë£Œ")
                        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                        if temp_video.exists():
                            temp_video.unlink()
                    else:
                        print(f"  âœ— ìë§‰ ì¶”ê°€ ì‹¤íŒ¨, ìë§‰ ì—†ëŠ” ì˜ìƒ ì‚¬ìš©")
                        # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë³µêµ¬
                        if temp_video.exists():
                            shutil.move(str(temp_video), str(output_video_path))

                except Exception as e:
                    print(f"  âœ— ìë§‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë³µêµ¬ ì‹œë„
                    if temp_video.exists() and not output_video_path.exists():
                        shutil.move(str(temp_video), str(output_video_path))

            print(f"âœ“ ì˜ìƒ ë Œë”ë§ ì™„ë£Œ: {output_video_path}")

            # ìµœì¢… ì˜ìƒ ì •ë³´ ì¶œë ¥
            self.print_video_info(output_video_path)

        return success

    def print_video_info(self, video_path: Path):
        """ì˜ìƒ ì •ë³´ ì¶œë ¥"""
        try:
            cmd = [
                "ffprobe",
                "-v", "error",
                "-show_entries", "format=duration,size",
                "-show_entries", "stream=width,height,codec_name",
                "-of", "json",
                str(video_path)
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            info = json.loads(result.stdout)

            if "format" in info:
                duration = float(info["format"].get("duration", 0))
                size = int(info["format"].get("size", 0)) / (1024 * 1024)  # MB

                print(f"\nì˜ìƒ ì •ë³´:")
                print(f"  - ê¸¸ì´: {duration:.1f}ì´ˆ")
                print(f"  - í¬ê¸°: {size:.1f}MB")

            if "streams" in info and len(info["streams"]) > 0:
                video_stream = info["streams"][0]
                print(f"  - í•´ìƒë„: {video_stream.get('width')}x{video_stream.get('height')}")
                print(f"  - ì½”ë±: {video_stream.get('codec_name')}")

        except Exception as e:
            print(f"âš  ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import sys
    from pathlib import Path

    project_root = Path(__file__).parent.parent.parent
    slides_json = project_root / "data" / "meta" / "slides.json"
    audio_meta = project_root / "data" / "meta" / "audio_meta.json"
    slides_img_dir = project_root / "data" / "temp" / "slides_img"
    audio_dir = project_root / "data" / "temp" / "audio"
    clips_dir = project_root / "data" / "temp" / "clips"
    output_video = project_root / "data" / "output" / "final.mp4"

    renderer = FFmpegRenderer()
    success = renderer.render_video(
        slides_json,
        audio_meta,
        slides_img_dir,
        audio_dir,
        clips_dir,
        output_video
    )

    if success:
        print(f"\nâœ“ ì„±ê³µ!")
    else:
        print(f"\nâœ— ì‹¤íŒ¨")
