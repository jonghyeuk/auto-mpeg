"""
í‚¤ì›Œë“œ ë§ˆì»¤ ëª¨ë“ˆ
ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ì—ì„œ í‚¤ì›Œë“œì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ ë™ê·¸ë¼ë¯¸/ë°‘ì¤„ë¡œ ë§ˆí‚¹
"""
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import fitz  # PyMuPDF
from PIL import Image, ImageDraw, ImageFont
import random


class KeywordMarker:
    """ìŠ¬ë¼ì´ë“œì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ì‹œê°ì ìœ¼ë¡œ ë§ˆí‚¹í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, use_ocr: bool = True):
        """
        Args:
            use_ocr: OCR ì‚¬ìš© ì—¬ë¶€ (PPT ì´ë¯¸ì§€ì˜ ê²½ìš°)
        """
        self.use_ocr = use_ocr
        self.ocr_reader = None

        if use_ocr:
            try:
                import easyocr
                self.ocr_reader = easyocr.Reader(['ko', 'en'], gpu=False)
            except ImportError:
                print("âš ï¸  EasyOCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OCR ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("   ì„¤ì¹˜: pip install easyocr")
                self.use_ocr = False

    def find_keyword_in_pdf(self, pdf_path: str, page_num: int, keyword: str) -> Optional[Tuple[float, float, float, float]]:
        """
        PDF í˜ì´ì§€ì—ì„œ í‚¤ì›Œë“œì˜ bbox(ì¢Œí‘œ) ì°¾ê¸°

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)
            keyword: ì°¾ì„ í‚¤ì›Œë“œ

        Returns:
            (x0, y0, x1, y1) bbox ë˜ëŠ” None
        """
        try:
            doc = fitz.open(pdf_path)
            page = doc[page_num]

            # í˜ì´ì§€ì˜ ëª¨ë“  ë‹¨ì–´ì™€ bbox ê°€ì ¸ì˜¤ê¸°
            words = page.get_text("words")  # [(x0, y0, x1, y1, "word", block_no, line_no, word_no)]

            # í‚¤ì›Œë“œ ì •ê·œí™” (ë„ì–´ì“°ê¸° ì œê±°, ì†Œë¬¸ì ë³€í™˜)
            keyword_normalized = keyword.lower().strip().replace(" ", "")

            # ë‹¨ì¼ ë‹¨ì–´ ë§¤ì¹­
            for word_info in words:
                word = word_info[4].lower().strip()
                word_normalized = word.replace(" ", "")

                # ì •ê·œí™”ëœ ë²„ì „ìœ¼ë¡œ ë¹„êµ (ë„ì–´ì“°ê¸° ë¬´ì‹œ)
                if keyword_normalized == word_normalized or keyword_normalized in word_normalized or word_normalized in keyword_normalized:
                    doc.close()
                    return (word_info[0], word_info[1], word_info[2], word_info[3])

            # ì—¬ëŸ¬ ë‹¨ì–´ ì—°ì† ë§¤ì¹­ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
            # "ê³µì • ì¥ë¹„ ì›ë¦¬"ë¥¼ ì°¾ê¸° ìœ„í•´ ì—°ì†ëœ ë‹¨ì–´ë“¤ í™•ì¸
            max_window = 10  # ìµœëŒ€ 10ê°œ ë‹¨ì–´ê¹Œì§€ ìœˆë„ìš°
            for window_size in range(1, min(max_window + 1, len(words) + 1)):
                for i in range(len(words) - window_size + 1):
                    # ìœˆë„ìš° ë‚´ ëª¨ë“  ë‹¨ì–´ í•©ì¹˜ê¸°
                    window_words = [words[i + j][4] for j in range(window_size)]
                    combined_text = "".join(window_words).lower().replace(" ", "")

                    # ì •ê·œí™”ëœ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    if keyword_normalized in combined_text or combined_text in keyword_normalized:
                        # ìœ ì‚¬ë„ í™•ì¸ (ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì œì™¸)
                        if len(combined_text) < len(keyword_normalized) * 3:  # ìµœëŒ€ 3ë°°ê¹Œì§€ í—ˆìš©
                            # ì—¬ëŸ¬ ë‹¨ì–´ì˜ bboxë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                            x0 = min(words[i + j][0] for j in range(window_size))
                            y0 = min(words[i + j][1] for j in range(window_size))
                            x1 = max(words[i + j][2] for j in range(window_size))
                            y1 = max(words[i + j][3] for j in range(window_size))
                            doc.close()
                            return (x0, y0, x1, y1)

            doc.close()
            return None

        except Exception as e:
            print(f"âš ï¸  PDFì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return None

    def find_keyword_in_image(self, image_path: str, keyword: str) -> Optional[Tuple[int, int, int, int]]:
        """
        ì´ë¯¸ì§€ì—ì„œ OCRë¡œ í‚¤ì›Œë“œì˜ bbox(ì¢Œí‘œ) ì°¾ê¸°

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            keyword: ì°¾ì„ í‚¤ì›Œë“œ

        Returns:
            (x0, y0, x1, y1) bbox ë˜ëŠ” None
        """
        if not self.use_ocr or self.ocr_reader is None:
            print("âš ï¸  OCR ë¦¬ë”ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        try:
            # OCR ìˆ˜í–‰
            results = self.ocr_reader.readtext(image_path)
            return self._find_keyword_in_ocr_results(keyword, results)

        except Exception as e:
            print(f"âš ï¸  ì´ë¯¸ì§€ì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸° ì‹¤íŒ¨: {e}")
            return None

    def _find_keyword_in_ocr_results(self, keyword: str, ocr_results: List) -> Optional[Tuple[int, int, int, int]]:
        """
        OCR ê²°ê³¼ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜)

        Args:
            keyword: ì°¾ì„ í‚¤ì›Œë“œ
            ocr_results: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Returns:
            (x0, y0, x1, y1) bbox ë˜ëŠ” None
        """
        # í‚¤ì›Œë“œ ì •ê·œí™” (ë„ì–´ì“°ê¸° ì œê±°, ì†Œë¬¸ì ë³€í™˜)
        keyword_normalized = keyword.lower().strip().replace(" ", "")

        # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë§¤ì¹­
        for (bbox, text, confidence) in ocr_results:
            if confidence < 0.3:  # ì‹ ë¢°ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ìŠ¤í‚µ
                continue

            text_normalized = text.lower().strip().replace(" ", "")

            # ì •ê·œí™”ëœ ë²„ì „ìœ¼ë¡œ ë¹„êµ (ë„ì–´ì“°ê¸° ë¬´ì‹œ)
            if keyword_normalized == text_normalized or keyword_normalized in text_normalized or text_normalized in keyword_normalized:
                # bboxëŠ” [[x0, y0], [x1, y0], [x1, y1], [x0, y1]] í˜•ì‹
                x0 = int(min(point[0] for point in bbox))
                y0 = int(min(point[1] for point in bbox))
                x1 = int(max(point[0] for point in bbox))
                y1 = int(max(point[1] for point in bbox))
                return (x0, y0, x1, y1)

        # ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì—°ì† ë§¤ì¹­ (ì¸ì ‘í•œ í…ìŠ¤íŠ¸ ë¸”ë¡ ê²°í•©)
        max_window = 10
        for window_size in range(1, min(max_window + 1, len(ocr_results) + 1)):
            for i in range(len(ocr_results) - window_size + 1):
                # ìœˆë„ìš° ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
                window_texts = [ocr_results[i + j][1] for j in range(window_size)]
                combined_text = "".join(window_texts).lower().replace(" ", "")

                # ì •ê·œí™”ëœ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if keyword_normalized in combined_text or combined_text in keyword_normalized:
                    # ìœ ì‚¬ë„ í™•ì¸ (ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì œì™¸)
                    if len(combined_text) < len(keyword_normalized) * 3:
                        # ì—¬ëŸ¬ bboxë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
                        all_points = []
                        for j in range(window_size):
                            all_points.extend(ocr_results[i + j][0])

                        x0 = int(min(point[0] for point in all_points))
                        y0 = int(min(point[1] for point in all_points))
                        x1 = int(max(point[0] for point in all_points))
                        y1 = int(max(point[1] for point in all_points))
                        return (x0, y0, x1, y1)

        return None

    def draw_circle_on_image(self, image_path: str, bbox: Tuple[float, float, float, float],
                            output_path: str, color: Tuple[int, int, int] = (255, 0, 0),
                            thickness: int = 5) -> bool:
        """
        ì´ë¯¸ì§€ì— í‚¤ì›Œë“œ ìœ„ì¹˜ì— ë™ê·¸ë¼ë¯¸ ê·¸ë¦¬ê¸°

        Args:
            image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
            bbox: (x0, y0, x1, y1) í‚¤ì›Œë“œ bbox
            output_path: ì €ì¥í•  ì´ë¯¸ì§€ ê²½ë¡œ
            color: BGR ìƒ‰ìƒ (ê¸°ë³¸: ë¹¨ê°„ìƒ‰)
            thickness: ì„  ë‘ê»˜

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì´ë¯¸ì§€ ì½ê¸°
            img = cv2.imread(str(image_path))
            if img is None:
                print(f"âš ï¸  ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                return False

            # bbox ì¤‘ì‹¬ê³¼ ë°˜ì§€ë¦„ ê³„ì‚°
            x0, y0, x1, y1 = bbox
            center_x = int((x0 + x1) / 2)
            center_y = int((y0 + y1) / 2)

            # íƒ€ì› ê·¸ë¦¬ê¸° (í…ìŠ¤íŠ¸ í¬ê¸°ì— ë§ê²Œ)
            width = int((x1 - x0) / 2) + 10
            height = int((y1 - y0) / 2) + 10

            cv2.ellipse(img, (center_x, center_y), (width, height), 0, 0, 360, color, thickness)

            # ì €ì¥
            cv2.imwrite(str(output_path), img)
            return True

        except Exception as e:
            print(f"âš ï¸  ë™ê·¸ë¼ë¯¸ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return False

    def draw_underline_on_image(self, image_path: str, bbox: Tuple[float, float, float, float],
                               output_path: str, color: Tuple[int, int, int] = (255, 0, 0),
                               thickness: int = 5) -> bool:
        """
        ì´ë¯¸ì§€ì— í‚¤ì›Œë“œ ìœ„ì¹˜ì— ë°‘ì¤„ ê·¸ë¦¬ê¸°

        Args:
            image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
            bbox: (x0, y0, x1, y1) í‚¤ì›Œë“œ bbox
            output_path: ì €ì¥í•  ì´ë¯¸ì§€ ê²½ë¡œ
            color: BGR ìƒ‰ìƒ (ê¸°ë³¸: ë¹¨ê°„ìƒ‰)
            thickness: ì„  ë‘ê»˜

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì´ë¯¸ì§€ ì½ê¸°
            img = cv2.imread(str(image_path))
            if img is None:
                print(f"âš ï¸  ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                return False

            # ë°‘ì¤„ ê·¸ë¦¬ê¸°
            x0, y0, x1, y1 = bbox
            y_line = int(y1) + 5  # í…ìŠ¤íŠ¸ ì•„ë˜ 5px

            cv2.line(img, (int(x0), y_line), (int(x1), y_line), color, thickness)

            # ì €ì¥
            cv2.imwrite(str(output_path), img)
            return True

        except Exception as e:
            print(f"âš ï¸  ë°‘ì¤„ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
            return False

    def create_transparent_overlay(self, image_width: int, image_height: int, bbox: Tuple[float, float, float, float],
                                  output_path: str, mark_style: str = "circle",
                                  color: Tuple[int, int, int, int] = (255, 0, 0, 255),
                                  thickness: int = 8) -> bool:
        """
        íˆ¬ëª… ë°°ê²½ì— ë§ˆí‚¹ë§Œ ê·¸ë¦° ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„± (FFmpeg overlayìš©)

        Args:
            image_width: ì›ë³¸ ì´ë¯¸ì§€ ë„ˆë¹„
            image_height: ì›ë³¸ ì´ë¯¸ì§€ ë†’ì´
            bbox: (x0, y0, x1, y1) í‚¤ì›Œë“œ bbox
            output_path: ì €ì¥í•  PNG ê²½ë¡œ
            mark_style: ë§ˆí‚¹ ìŠ¤íƒ€ì¼ ("circle" ë˜ëŠ” "underline")
            color: BGRA ìƒ‰ìƒ (ê¸°ë³¸: ë¹¨ê°„ìƒ‰, ë¶ˆíˆ¬ëª…)
            thickness: ì„  ë‘ê»˜

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± (BGRA)
            overlay = np.zeros((image_height, image_width, 4), dtype=np.uint8)

            x0, y0, x1, y1 = bbox
            original_bbox = (x0, y0, x1, y1)

            # bboxë¥¼ ì´ë¯¸ì§€ í•´ìƒë„ ë‚´ë¡œ í´ë¦¬í•‘ (ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡)
            x0 = max(0, min(x0, image_width))
            y0 = max(0, min(y0, image_height))
            x1 = max(0, min(x1, image_width))
            y1 = max(0, min(y1, image_height))

            # í´ë¦¬í•‘ í›„ bboxê°€ ìœ íš¨í•œì§€ í™•ì¸
            if x0 >= x1 or y0 >= y1:
                print(f"âš ï¸  í´ë¦¬í•‘ í›„ bbox ë¬´íš¨: {original_bbox} â†’ ({x0}, {y0}, {x1}, {y1})")
                return False

            if mark_style == "circle":
                # íƒ€ì› ê·¸ë¦¬ê¸°
                center_x = int((x0 + x1) / 2)
                center_y = int((y0 + y1) / 2)
                width = int((x1 - x0) / 2) + 15
                height = int((y1 - y0) / 2) + 15

                # íƒ€ì›ì´ ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í¬ê¸° ì œí•œ
                margin = 10  # ì•ˆì „ ë§ˆì§„
                max_width = min(width, center_x - margin, image_width - center_x - margin)
                max_height = min(height, center_y - margin, image_height - center_y - margin)

                # í¬ê¸°ê°€ ìœ íš¨í•œ ê²½ìš°ì—ë§Œ ê·¸ë¦¬ê¸°
                if max_width > 0 and max_height > 0:
                    cv2.ellipse(overlay, (center_x, center_y), (max_width, max_height), 0, 0, 360, color, thickness)

            else:  # underline
                # ë°‘ì¤„ ê·¸ë¦¬ê¸°
                y_line = int(y1) + 5
                # y ì¢Œí‘œë„ í´ë¦¬í•‘
                y_line = max(0, min(y_line, image_height - 1))
                cv2.line(overlay, (int(x0), y_line), (int(x1), y_line), color, thickness)

            # PNGë¡œ ì €ì¥ (íˆ¬ëª…ë„ ìœ ì§€)
            cv2.imwrite(str(output_path), overlay)
            return True

        except Exception as e:
            print(f"âš ï¸  íˆ¬ëª… ì˜¤ë²„ë ˆì´ ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def _bbox_overlap(self, bbox1: Tuple[float, float, float, float],
                      bbox2: Tuple[float, float, float, float],
                      threshold: float = 0.5) -> bool:
        """
        ë‘ bboxê°€ ì¼ì • ë¹„ìœ¨ ì´ìƒ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸

        Args:
            bbox1: (x0, y0, x1, y1)
            bbox2: (x0, y0, x1, y1)
            threshold: ê²¹ì¹¨ ë¹„ìœ¨ ì„ê³„ê°’ (0.5 = 50% ì´ìƒ ê²¹ì¹˜ë©´ True)

        Returns:
            ê²¹ì¹¨ ì—¬ë¶€
        """
        x0_1, y0_1, x1_1, y1_1 = bbox1
        x0_2, y0_2, x1_2, y1_2 = bbox2

        # ê²¹ì¹˜ëŠ” ì˜ì—­ ê³„ì‚°
        x0_inter = max(x0_1, x0_2)
        y0_inter = max(y0_1, y0_2)
        x1_inter = min(x1_1, x1_2)
        y1_inter = min(y1_1, y1_2)

        # ê²¹ì¹˜ëŠ” ì˜ì—­ì´ ì—†ìœ¼ë©´ False
        if x0_inter >= x1_inter or y0_inter >= y1_inter:
            return False

        # ê²¹ì¹˜ëŠ” ë©´ì 
        inter_area = (x1_inter - x0_inter) * (y1_inter - y0_inter)

        # ê° bboxì˜ ë©´ì 
        area1 = (x1_1 - x0_1) * (y1_1 - y0_1)
        area2 = (x1_2 - x0_2) * (y1_2 - y0_2)

        # ë” ì‘ì€ bbox ê¸°ì¤€ìœ¼ë¡œ ê²¹ì¹¨ ë¹„ìœ¨ ê³„ì‚°
        min_area = min(area1, area2)
        if min_area <= 0:
            return False

        overlap_ratio = inter_area / min_area
        return overlap_ratio >= threshold

    def _is_nearby_marked(self, bbox: Tuple[float, float, float, float],
                          marked_bboxes: List[Tuple[float, float, float, float]],
                          distance_threshold: float = 50) -> bool:
        """
        bboxê°€ ì´ë¯¸ ë§ˆí‚¹ëœ ìœ„ì¹˜ì™€ ê°€ê¹Œìš´ì§€ í™•ì¸

        Args:
            bbox: í™•ì¸í•  bbox (x0, y0, x1, y1)
            marked_bboxes: ì´ë¯¸ ë§ˆí‚¹ëœ bbox ë¦¬ìŠ¤íŠ¸
            distance_threshold: ê±°ë¦¬ ì„ê³„ê°’ (í”½ì…€)

        Returns:
            ê°€ê¹Œìš´ ë§ˆí‚¹ì´ ìˆìœ¼ë©´ True
        """
        if not marked_bboxes:
            return False

        x0, y0, x1, y1 = bbox
        center_x = (x0 + x1) / 2
        center_y = (y0 + y1) / 2

        for marked_bbox in marked_bboxes:
            # ê²¹ì¹¨ í™•ì¸
            if self._bbox_overlap(bbox, marked_bbox, threshold=0.3):
                return True

            # ì¤‘ì‹¬ì  ê±°ë¦¬ í™•ì¸
            mx0, my0, mx1, my1 = marked_bbox
            marked_center_x = (mx0 + mx1) / 2
            marked_center_y = (my0 + my1) / 2

            distance = ((center_x - marked_center_x) ** 2 + (center_y - marked_center_y) ** 2) ** 0.5
            if distance < distance_threshold:
                return True

        return False

    def mark_keywords_on_slide(self, slide_image_path: str, keywords: List[Dict],
                               output_dir: Path, pdf_path: Optional[str] = None,
                               page_num: Optional[int] = None,
                               mark_style: str = "circle",
                               create_overlay: bool = True) -> List[Dict]:
        """
        ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ì— ì—¬ëŸ¬ í‚¤ì›Œë“œ ë§ˆí‚¹

        Args:
            slide_image_path: ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ê²½ë¡œ
            keywords: [{"text": "í‚¤ì›Œë“œ", "timing": 2.5}, ...] ë¦¬ìŠ¤íŠ¸
            output_dir: ë§ˆí‚¹ëœ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ (PDFì¸ ê²½ìš°)
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (PDFì¸ ê²½ìš°, 0ë¶€í„° ì‹œì‘)
            mark_style: ë§ˆí‚¹ ìŠ¤íƒ€ì¼ ("circle" ë˜ëŠ” "underline")
            create_overlay: Trueì´ë©´ íˆ¬ëª… ì˜¤ë²„ë ˆì´ ìƒì„±, Falseì´ë©´ ì§ì ‘ ê·¸ë¦¬ê¸°

        Returns:
            [{"keyword": "í‚¤ì›Œë“œ", "timing": 2.5, "overlay_image": "path", "bbox": (x0,y0,x1,y1), "found": True}, ...]
        """
        output_dir.mkdir(parents=True, exist_ok=True)
        results = []

        # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        img = cv2.imread(str(slide_image_path))
        if img is None:
            print(f"âš ï¸  ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {slide_image_path}")
            return results

        img_height, img_width = img.shape[:2]

        # ì´ë¯¸ ë§ˆí‚¹ëœ bbox ì¶”ì  (ì¤‘ë³µ ë°©ì§€ìš©)
        marked_bboxes = []

        # OCR ê²°ê³¼ ìºì‹±: PPTì¸ ê²½ìš°(PDF ì•„ë‹Œ ê²½ìš°) í•œ ë²ˆë§Œ OCR ì‹¤í–‰
        ocr_cache = None
        if self.use_ocr and (pdf_path is None):
            try:
                print(f"ğŸ” OCR ì‹¤í–‰ ì¤‘ (1íšŒë§Œ)...")
                ocr_cache = self.ocr_reader.readtext(slide_image_path)
                print(f"  âœ“ OCR ì™„ë£Œ: {len(ocr_cache)}ê°œ í…ìŠ¤íŠ¸ ë¸”ë¡ ë°œê²¬")
            except Exception as e:
                print(f"  âš ï¸  OCR ì‹¤íŒ¨: {e}")

        for i, kw in enumerate(keywords):
            keyword_text = kw.get("text", "")
            timing = kw.get("timing", 0)

            # ê° í‚¤ì›Œë“œë§ˆë‹¤ ëœë¤í•˜ê²Œ ìŠ¤íƒ€ì¼ ì„ íƒ (ë™ê·¸ë¼ë¯¸ ë˜ëŠ” ë°‘ì¤„)
            current_style = random.choice(["circle", "underline"])

            # í‚¤ì›Œë“œ ìœ„ì¹˜ ì°¾ê¸°
            bbox = None

            # PDFì¸ ê²½ìš° PDFì—ì„œ ì§ì ‘ ì°¾ê¸°
            if pdf_path and page_num is not None:
                bbox = self.find_keyword_in_pdf(pdf_path, page_num, keyword_text)

                # PDFì—ì„œ ì°¾ì€ bboxë¥¼ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                if bbox:
                    # PDF í˜ì´ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                    doc = fitz.open(pdf_path)
                    page = doc[page_num]
                    pdf_width = page.rect.width
                    pdf_height = page.rect.height
                    doc.close()

                    # ë Œë”ë§ ì‹œ DPI ìŠ¤ì¼€ì¼ (150 DPI)
                    dpi_scale = 150 / 72
                    rendered_width = pdf_width * dpi_scale
                    rendered_height = pdf_height * dpi_scale

                    # ëª©í‘œ í¬ê¸°ì— ë§ì¶° ìŠ¤ì¼€ì¼ ê³„ì‚° (pdf_parser.pyì™€ ë™ì¼)
                    scale = min(img_width / rendered_width, img_height / rendered_height)
                    new_width = int(rendered_width * scale)
                    new_height = int(rendered_height * scale)

                    # ì¤‘ì•™ ì •ë ¬ íŒ¨ë”© ì˜¤í”„ì…‹ (pdf_parser.pyì™€ ë™ì¼)
                    pad_x = (img_width - new_width) // 2
                    pad_y = (img_height - new_height) // 2

                    print(f"    ğŸ“Š PDF bbox: {bbox}")
                    print(f"    ğŸ“ PDF í¬ê¸°: {pdf_width:.1f}x{pdf_height:.1f}")
                    print(f"    ğŸ–¼ï¸  ë Œë”ë§ í¬ê¸°: {rendered_width:.1f}x{rendered_height:.1f}")
                    print(f"    ğŸ“ ìŠ¤ì¼€ì¼ í›„: {new_width}x{new_height}, íŒ¨ë”©: ({pad_x}, {pad_y})")

                    # PDF ì¢Œí‘œê³„ â†’ ì´ë¯¸ì§€ ì¢Œí‘œê³„ ë³€í™˜
                    # 1. DPI ìŠ¤ì¼€ì¼ ì ìš©
                    # 2. Yì¶• ë’¤ì§‘ê¸° (PDFëŠ” ì™¼ìª½ ì•„ë˜ ì›ì )
                    # 3. ìŠ¤ì¼€ì¼ ì ìš©
                    # 4. íŒ¨ë”© ì˜¤í”„ì…‹ ì¶”ê°€
                    bbox = (
                        bbox[0] * dpi_scale * scale + pad_x,
                        (pdf_height - bbox[3]) * dpi_scale * scale + pad_y,
                        bbox[2] * dpi_scale * scale + pad_x,
                        (pdf_height - bbox[1]) * dpi_scale * scale + pad_y
                    )
                    print(f"    âœ… ë³€í™˜ëœ bbox: ({bbox[0]:.1f}, {bbox[1]:.1f}, {bbox[2]:.1f}, {bbox[3]:.1f})")

            # OCRë¡œ ì°¾ê¸° (PDFì—ì„œ ëª» ì°¾ì•˜ê±°ë‚˜ PPTì¸ ê²½ìš°)
            # ìºì‹œëœ OCR ê²°ê³¼ ì‚¬ìš© (1íšŒë§Œ ì‹¤í–‰)
            if bbox is None and ocr_cache is not None:
                bbox = self._find_keyword_in_ocr_results(keyword_text, ocr_cache)
                if bbox:
                    print(f"    ğŸ“Š OCR bbox: {bbox}")

            # ë§ˆí‚¹í•˜ê¸°
            if bbox:
                # bbox ìœ íš¨ì„± ê²€ì¦
                x0, y0, x1, y1 = bbox
                if x0 < 0 or y0 < 0 or x1 > img_width or y1 > img_height or x0 >= x1 or y0 >= y1:
                    print(f"    âš ï¸  bbox ë²”ìœ„ ì´ˆê³¼ ë˜ëŠ” ì˜ëª»ë¨: {bbox} (ì´ë¯¸ì§€: {img_width}x{img_height})")
                    print(f"    â†’ í´ë¦¬í•‘ ì ìš©")

                # ì¤‘ë³µ ë§ˆí‚¹ ë°©ì§€: ì´ë¯¸ ë§ˆí‚¹ëœ ìœ„ì¹˜ì™€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
                if self._is_nearby_marked(bbox, marked_bboxes, distance_threshold=80):
                    print(f"    âš ï¸  í‚¤ì›Œë“œ '{keyword_text}' ì¤‘ë³µ ìœ„ì¹˜ - ìŠ¤í‚µ (ì´ë¯¸ ë§ˆí‚¹ëœ ì˜ì—­ê³¼ ê²¹ì¹¨)")
                    results.append({
                        "keyword": keyword_text,
                        "timing": timing,
                        "overlay_image": None,
                        "bbox": bbox,
                        "found": False,
                        "skipped_reason": "duplicate_location"
                    })
                    continue

                if create_overlay:
                    # íˆ¬ëª… ì˜¤ë²„ë ˆì´ ìƒì„± (FFmpegìš©)
                    # í•œê¸€ íŒŒì¼ëª… ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì¸ë±ìŠ¤ ê¸°ë°˜ íŒŒì¼ëª… ì‚¬ìš©
                    output_path = output_dir / f"overlay_{i}.png"
                    success = self.create_transparent_overlay(
                        img_width, img_height, bbox, str(output_path),
                        mark_style=current_style,  # ëœë¤ ìŠ¤íƒ€ì¼ ì‚¬ìš©
                        color=(0, 0, 255, 255),  # BGRA - ë¹¨ê°„ìƒ‰
                        thickness=8
                    )
                else:
                    # ì§ì ‘ ê·¸ë¦¬ê¸°
                    output_path = output_dir / f"marked_{i}.png"
                    if current_style == "circle":  # ëœë¤ ìŠ¤íƒ€ì¼ ì‚¬ìš©
                        success = self.draw_circle_on_image(slide_image_path, bbox, str(output_path))
                    else:  # underline
                        success = self.draw_underline_on_image(slide_image_path, bbox, str(output_path))

                if success:
                    # ì„±ê³µì ìœ¼ë¡œ ë§ˆí‚¹ëœ bboxë¥¼ ì¶”ì  ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    marked_bboxes.append(bbox)
                    results.append({
                        "keyword": keyword_text,
                        "timing": timing,
                        "overlay_image": str(output_path),
                        "bbox": bbox,
                        "found": True
                    })
                    print(f"âœ“ í‚¤ì›Œë“œ '{keyword_text}' ë§ˆí‚¹ ì™„ë£Œ: {output_path}")
                else:
                    results.append({
                        "keyword": keyword_text,
                        "timing": timing,
                        "overlay_image": None,
                        "bbox": None,
                        "found": False
                    })
                    print(f"âš ï¸  í‚¤ì›Œë“œ '{keyword_text}' ë§ˆí‚¹ ì‹¤íŒ¨")
            else:
                results.append({
                    "keyword": keyword_text,
                    "timing": timing,
                    "overlay_image": None,
                    "bbox": None,
                    "found": False
                })
                print(f"âš ï¸  í‚¤ì›Œë“œ '{keyword_text}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        return results

    def find_text_position(self, slide_image_path: str, search_text: str,
                           pdf_path: str = None, page_num: int = None) -> List[Dict]:
        """
        ìŠ¬ë¼ì´ë“œì—ì„œ íŠ¹ì • í…ìŠ¤íŠ¸ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ ë°˜í™˜ (í™”ì‚´í‘œ í¬ì¸í„°ìš©)

        Args:
            slide_image_path: ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ê²½ë¡œ
            search_text: ì°¾ì„ í…ìŠ¤íŠ¸ (ì˜ˆ: "$1", "$2")
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ (ì„ íƒ)
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (ì„ íƒ)

        Returns:
            list: [{"x": ì¤‘ì‹¬x, "y": ì¤‘ì‹¬y, "bbox": (x0,y0,x1,y1), "text": ë§¤ì¹­ëœí…ìŠ¤íŠ¸}, ...]
        """
        import re
        results = []

        # PDFì—ì„œ ë¨¼ì € ì°¾ê¸°
        if pdf_path and page_num is not None:
            bbox = self.find_keyword_in_pdf(pdf_path, page_num, search_text)
            if bbox:
                # PDF ì¢Œí‘œ â†’ ì´ë¯¸ì§€ ì¢Œí‘œ ë³€í™˜ í•„ìš”
                # (ê°„ë‹¨í•˜ê²Œ OCR ê²°ê³¼ ì‚¬ìš©ìœ¼ë¡œ ëŒ€ì²´)
                pass

        # OCRë¡œ ì°¾ê¸°
        if self.use_ocr and self.ocr_reader:
            try:
                ocr_results = self.ocr_reader.readtext(slide_image_path)

                # ì •ê·œí™”ëœ ê²€ìƒ‰ í…ìŠ¤íŠ¸
                search_normalized = search_text.lower().strip()

                # $ìˆ«ì íŒ¨í„´ íŠ¹ë³„ ì²˜ë¦¬ (ì˜ˆ: "$1", "$2")
                # OCRì´ "$"ë¥¼ "S", "5", "s" ë“±ìœ¼ë¡œ ì˜ëª» ì¸ì‹í•  ìˆ˜ ìˆìŒ
                is_dollar_pattern = search_text.startswith("$") and len(search_text) >= 2

                if is_dollar_pattern:
                    # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ (ì˜ˆ: "$1" -> "1", "$12" -> "12")
                    number_part = search_text[1:]

                    # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•œ ì •ê·œì‹ íŒ¨í„´ë“¤
                    # $3ì„ ì°¾ì„ ë•Œ "3", "$3", "S3", "s3", "53" ë“± ì •í™•íˆ ë§¤ì¹­
                    # í•˜ì§€ë§Œ "13", "23", "30", "3ë‹¨ê³„" ë“±ì€ ì œì™¸
                    exact_patterns = [
                        rf'^[\$sS5]?{re.escape(number_part)}$',  # ì •í™•íˆ ì¼ì¹˜ (ì˜ˆ: "$3", "S3", "3")
                        rf'^[\$sS5]{re.escape(number_part)}[.,:]?$',  # ë’¤ì— êµ¬ë‘ì  (ì˜ˆ: "$3.", "$3,")
                    ]

                    print(f"    ğŸ” í™”ì‚´í‘œ ë§ˆì»¤ '{search_text}' ê²€ìƒ‰ ì¤‘... (ì •í™•í•œ ë§¤ì¹­)")

                    for (bbox, text, confidence) in ocr_results:
                        if confidence < 0.2:
                            continue

                        text_clean = text.strip()

                        # ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­
                        for pattern in exact_patterns:
                            if re.match(pattern, text_clean, re.IGNORECASE):
                                x0 = int(min(point[0] for point in bbox))
                                y0 = int(min(point[1] for point in bbox))
                                x1 = int(max(point[0] for point in bbox))
                                y1 = int(max(point[1] for point in bbox))

                                center_x = (x0 + x1) // 2
                                center_y = (y0 + y1) // 2

                                results.append({
                                    "x": center_x,
                                    "y": center_y,
                                    "bbox": (x0, y0, x1, y1),
                                    "text": text_clean,
                                    "confidence": confidence
                                })
                                print(f"    âœ“ í™”ì‚´í‘œ ë§ˆì»¤ ì •í™• ë§¤ì¹­: '{search_text}' -> '{text_clean}' (ì‹ ë¢°ë„: {confidence:.2f})")
                                break

                    # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ë” ì—„ê²©í•˜ê²Œ)
                    if not results:
                        print(f"    âš ï¸ ì •í™•í•œ ë§¤ì¹­ ì—†ìŒ, ë¶€ë¶„ ë§¤ì¹­ ì‹œë„...")
                        for (bbox, text, confidence) in ocr_results:
                            if confidence < 0.3:  # ë¶€ë¶„ ë§¤ì¹­ì€ ë” ë†’ì€ ì‹ ë¢°ë„ ìš”êµ¬
                                continue

                            text_clean = text.strip()
                            # í…ìŠ¤íŠ¸ê°€ ì§§ê³  (5ì ì´í•˜) ìˆ«ì ë¶€ë¶„ì´ ì •í™•íˆ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë§¤ì¹­
                            if len(text_clean) <= 5:
                                # ìˆ«ìê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ (ì•ë’¤ì— ë‹¤ë¥¸ ìˆ«ì ì—†ì´)
                                if re.search(rf'(?<![0-9]){re.escape(number_part)}(?![0-9])', text_clean):
                                    x0 = int(min(point[0] for point in bbox))
                                    y0 = int(min(point[1] for point in bbox))
                                    x1 = int(max(point[0] for point in bbox))
                                    y1 = int(max(point[1] for point in bbox))

                                    center_x = (x0 + x1) // 2
                                    center_y = (y0 + y1) // 2

                                    results.append({
                                        "x": center_x,
                                        "y": center_y,
                                        "bbox": (x0, y0, x1, y1),
                                        "text": text_clean,
                                        "confidence": confidence
                                    })
                                    print(f"    âœ“ í™”ì‚´í‘œ ë§ˆì»¤ ë¶€ë¶„ ë§¤ì¹­: '{search_text}' -> '{text_clean}' (ì‹ ë¢°ë„: {confidence:.2f})")
                else:
                    # ì¼ë°˜ í…ìŠ¤íŠ¸ ë§¤ì¹­
                    for (bbox, text, confidence) in ocr_results:
                        if confidence < 0.3:
                            continue

                        text_normalized = text.lower().strip()

                        if search_normalized == text_normalized or search_normalized in text_normalized:
                            x0 = int(min(point[0] for point in bbox))
                            y0 = int(min(point[1] for point in bbox))
                            x1 = int(max(point[0] for point in bbox))
                            y1 = int(max(point[1] for point in bbox))

                            center_x = (x0 + x1) // 2
                            center_y = (y0 + y1) // 2

                            results.append({
                                "x": center_x,
                                "y": center_y,
                                "bbox": (x0, y0, x1, y1),
                                "text": text,
                                "confidence": confidence
                            })

            except Exception as e:
                print(f"âš ï¸  í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì°¾ê¸° ì‹¤íŒ¨: {e}")

        # ê²°ê³¼ê°€ ì—¬ëŸ¬ ê°œë©´ ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ê²ƒ ì„ íƒ
        if len(results) > 1:
            results.sort(key=lambda x: x["confidence"], reverse=True)
            print(f"    ğŸ“Š {len(results)}ê°œ ë§¤ì¹­ ì¤‘ ì‹ ë¢°ë„ ìµœê³ : '{results[0]['text']}' (ì‹ ë¢°ë„: {results[0]['confidence']:.2f})")
            results = [results[0]]  # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ê²ƒë§Œ ë°˜í™˜

        # $ìˆ«ì íŒ¨í„´ ê²°ê³¼ ë¡œê¹… (ë¸”ë¡ ë°–ì—ì„œ ë³€ìˆ˜ í™•ì¸)
        is_dollar_pattern_check = search_text.startswith("$") and len(search_text) >= 2
        if is_dollar_pattern_check and not results:
            print(f"    âš ï¸ í™”ì‚´í‘œ ë§ˆì»¤ '{search_text}'ë¥¼ ì°¾ì§€ ëª»í•¨ (í°ìƒ‰ ê¸€ì”¨ëŠ” OCR ì¸ì‹ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ)")

        return results

    def remove_markers_from_image(self, image_path: str, bboxes: List[Tuple[int, int, int, int]],
                                   output_path: str = None, method: str = "inpaint") -> str:
        """
        ì´ë¯¸ì§€ì—ì„œ ë§ˆì»¤ ì˜ì—­ì„ ì œê±° (ì£¼ë³€ ìƒ‰ìƒìœ¼ë¡œ ì±„ì›€)

        Args:
            image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
            bboxes: ì œê±°í•  ì˜ì—­ë“¤ [(x0, y0, x1, y1), ...]
            output_path: ì¶œë ¥ ê²½ë¡œ (Noneì´ë©´ ì›ë³¸ ë®ì–´ì“°ê¸°)
            method: 'inpaint' (OpenCV ì¸í˜ì¸íŒ…) ë˜ëŠ” 'fill' (ì£¼ë³€ìƒ‰ ì±„ìš°ê¸°)

        Returns:
            ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œ
        """
        if not bboxes:
            return image_path

        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(image_path)
        if img is None:
            print(f"âš ï¸ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return image_path

        height, width = img.shape[:2]

        if method == "inpaint":
            # OpenCV ì¸í˜ì¸íŒ… ì‚¬ìš© (ìì—°ìŠ¤ëŸ¬ìš´ ì œê±°)
            mask = np.zeros((height, width), dtype=np.uint8)

            for bbox in bboxes:
                x0, y0, x1, y1 = bbox
                # bboxì— ì•½ê°„ì˜ ì—¬ìœ  ì¶”ê°€
                padding = 3
                x0 = max(0, x0 - padding)
                y0 = max(0, y0 - padding)
                x1 = min(width, x1 + padding)
                y1 = min(height, y1 + padding)

                # ë§ˆìŠ¤í¬ì— ì œê±°í•  ì˜ì—­ í‘œì‹œ
                cv2.rectangle(mask, (x0, y0), (x1, y1), 255, -1)

            # ì¸í˜ì¸íŒ… ì ìš©
            result = cv2.inpaint(img, mask, inpaintRadius=5, flags=cv2.INPAINT_TELEA)

        else:  # method == "fill"
            result = img.copy()

            for bbox in bboxes:
                x0, y0, x1, y1 = bbox
                padding = 3
                x0 = max(0, x0 - padding)
                y0 = max(0, y0 - padding)
                x1 = min(width, x1 + padding)
                y1 = min(height, y1 + padding)

                # ì£¼ë³€ í”½ì…€ì—ì„œ ìƒ‰ìƒ ìƒ˜í”Œë§ (bbox ë°”ë¡œ ë°”ê¹¥ ì˜ì—­)
                sample_region = []

                # ìœ„ìª½ ê°€ì¥ìë¦¬
                if y0 > 0:
                    sample_region.extend(img[max(0, y0-5):y0, x0:x1].reshape(-1, 3).tolist())
                # ì•„ë˜ìª½ ê°€ì¥ìë¦¬
                if y1 < height:
                    sample_region.extend(img[y1:min(height, y1+5), x0:x1].reshape(-1, 3).tolist())
                # ì™¼ìª½ ê°€ì¥ìë¦¬
                if x0 > 0:
                    sample_region.extend(img[y0:y1, max(0, x0-5):x0].reshape(-1, 3).tolist())
                # ì˜¤ë¥¸ìª½ ê°€ì¥ìë¦¬
                if x1 < width:
                    sample_region.extend(img[y0:y1, x1:min(width, x1+5)].reshape(-1, 3).tolist())

                if sample_region:
                    # ì£¼ë³€ ìƒ‰ìƒì˜ ì¤‘ì•™ê°’ ì‚¬ìš©
                    fill_color = np.median(sample_region, axis=0).astype(np.uint8)
                else:
                    # ê¸°ë³¸ê°’: ê²€ì •ìƒ‰
                    fill_color = np.array([0, 0, 0], dtype=np.uint8)

                # ì˜ì—­ ì±„ìš°ê¸°
                cv2.rectangle(result, (x0, y0), (x1, y1), fill_color.tolist(), -1)

        # ì €ì¥
        if output_path is None:
            output_path = image_path

        cv2.imwrite(output_path, result)
        print(f"âœ“ ë§ˆì»¤ {len(bboxes)}ê°œ ì œê±° ì™„ë£Œ: {output_path}")

        return output_path


def remove_markers_from_slides(slides_dir: Path, arrow_pointers_by_slide: Dict, output_dir: Path = None):
    """
    ì—¬ëŸ¬ ìŠ¬ë¼ì´ë“œì—ì„œ ë§ˆì»¤ ì œê±° (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜)

    Args:
        slides_dir: ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        arrow_pointers_by_slide: {slide_index: [arrow_pointer, ...], ...}
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì›ë³¸ ë””ë ‰í† ë¦¬)
    """
    marker = KeywordMarker(use_ocr=False)  # OCR ë¶ˆí•„ìš”

    for slide_idx, arrow_pointers in arrow_pointers_by_slide.items():
        slide_path = slides_dir / f"slide_{slide_idx:03d}.png"
        if not slide_path.exists():
            continue

        bboxes = []
        for arrow in arrow_pointers:
            bbox = arrow.get("marker_bbox")
            if bbox:
                bboxes.append(bbox)

        if bboxes:
            output_path = None
            if output_dir:
                output_dir.mkdir(parents=True, exist_ok=True)
                output_path = str(output_dir / f"slide_{slide_idx:03d}.png")

            marker.remove_markers_from_image(str(slide_path), bboxes, output_path)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    marker = KeywordMarker(use_ocr=True)

    # PDF í…ŒìŠ¤íŠ¸
    test_pdf = "/path/to/test.pdf"
    test_keywords = [
        {"text": "ë¨¸ì‹ ëŸ¬ë‹", "timing": 2.5},
        {"text": "ì‹ ê²½ë§", "timing": 5.0}
    ]

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    # results = marker.mark_keywords_on_slide(
    #     slide_image_path="/path/to/slide.png",
    #     keywords=test_keywords,
    #     output_dir=Path("./marked_slides"),
    #     pdf_path=test_pdf,
    #     page_num=0,
    #     mark_style="circle"
    # )
